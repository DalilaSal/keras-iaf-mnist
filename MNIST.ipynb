{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Add\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from distributions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean_0 = Dense(latent_dim)(h)\n",
    "z_std_0 = Dense(latent_dim, activation=\"softplus\")(h)\n",
    "hp = Dense(latent_dim)(h)\n",
    "encoder = Model(x, [z_mean_0,z_std_0, hp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Latent models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _mask_matrix_made(dim):\n",
    "    \"\"\"\n",
    "    see https://arxiv.org/pdf/1502.03509.pdf\n",
    "    Section 4 explains how to define the masks\n",
    "    \"\"\"\n",
    "    mask_vector = np.random.randint(1, dim, dim)\n",
    "    mask_matrix0 = np.fromfunction(lambda k, d: mask_vector[k] >= d, (dim, dim), dtype=int).astype(np.int32).astype(np.float32)\n",
    "    mask_matrix1 = np.fromfunction(lambda d, k: d > mask_vector[k], (dim, dim), dtype=int).astype(np.int32).astype(np.float32)\n",
    "    return mask_matrix0, mask_matrix1\n",
    "\n",
    "\n",
    "def MADE(mask_matrix0, mask_matrix1, latent_dim, activation=None):\n",
    "    \"\"\"\n",
    "    2-layered MADE model\n",
    "    see https://arxiv.org/pdf/1502.03509.pdf\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        hl = MaskedDense(latent_dim, mask=mask_matrix0)(x)\n",
    "        hl = PReLU()(hl)\n",
    "        hl = MaskedDense(latent_dim, mask=mask_matrix1, activation=activation)(hl)\n",
    "        return hl\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_latent = 10\n",
    "latent_models = []\n",
    "\n",
    "masks = [_mask_matrix_made(latent_dim) for k in range(n_latent)]\n",
    "    \n",
    "for k in range(n_latent):\n",
    "    latent_input = Input(shape=(latent_dim,), batch_shape=(batch_size, latent_dim))\n",
    "\n",
    "    mask0, mask1 = masks[k]\n",
    "    mean = MADE(mask0, mask1, latent_dim)(latent_input)\n",
    "    std = MADE(mask0, mask1, latent_dim, activation=\"sigmoid\")(latent_input)\n",
    "\n",
    "    latent_model = Model(latent_input, [mean, std])\n",
    "    latent_models.append(latent_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_eps(batch_size, latent_dim, epsilon_std):\n",
    "    \"\"\"Create a function to sample N(0, epsilon_std) vectors\"\"\"\n",
    "    return lambda args: K.random_normal(shape=(batch_size, latent_dim),\n",
    "                                        mean=0.,\n",
    "                                        stddev=epsilon_std)\n",
    "def sample_z0(args):\n",
    "    \"\"\"Sample from N(mu, sigma) where sigma is the stddev !!!\"\"\"\n",
    "    z_mean, z_std, epsilon = args\n",
    "    z0 = z_mean + K.exp(K.log(z_std + 1e-8)) * epsilon\n",
    "    return z0\n",
    "def iaf_transform_z(args):\n",
    "    \"\"\"Apply the IAF transform to input z\"\"\"\n",
    "    z, mean, std = args\n",
    "    z_ = z\n",
    "    z_ *= std\n",
    "    z_ += (1 - std) * mean\n",
    "    return z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eps = Lambda(sample_eps(batch_size, latent_dim, epsilon_std), name='sample_eps')([z_mean_0, z_std_0])\n",
    "z0 = Lambda(sample_z0, name='sample_z0')([z_mean_0, z_std_0, eps])\n",
    "\n",
    "z_means = [z_mean_0]\n",
    "z_stds = [z_std_0]\n",
    "zs = [z0]\n",
    "for latent_model in latent_models:\n",
    "    zz = Add()([Dense(latent_dim, activation='relu')(hp), zs[-1]])\n",
    "    z_mean, z_std = latent_model(zz)\n",
    "    z_means.append(z_mean)\n",
    "    z_stds.append(z_std)\n",
    "    z = Lambda(iaf_transform_z)([zs[-1], z_mean, z_std])\n",
    "    zs.append(z)\n",
    "z = zs[-1]\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_stdnormal(x):\n",
    "    \"\"\"log density of a standard gaussian\"\"\"\n",
    "    c = - 0.5 * math.log(2*math.pi)\n",
    "    result = c - K.square(x) / 2\n",
    "    return result\n",
    "\n",
    "def log_normal2(x, mean, log_var):\n",
    "    \"\"\"log density of N(mu, sigma)\"\"\"\n",
    "    c = - 0.5 * math.log(2*math.pi)\n",
    "    result = c - log_var/2 - K.square(x - mean) / (2 * K.exp(log_var) + 1e-8)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_sample = 20\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    # kl divergence\n",
    "    # sampling for estimating the expectations\n",
    "    for k in range(n_sample):\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=1.0)  # used for every z_i sampling\n",
    "        z0_ = z_mean_0 + K.exp(K.log(z_std_0+1e-8)) * epsilon\n",
    "        z_ = z0_\n",
    "        for z_mean, z_std in zip(z_means[1:], z_stds[1:]):\n",
    "            z_ = iaf_transform_z([z_, z_mean, z_std])\n",
    "\n",
    "        try:\n",
    "            loss += K.sum(log_normal2(z0_, z_mean_0, 2*K.log(z_std_0+1e-8)), -1)\n",
    "        except NameError:\n",
    "            loss = K.sum(log_normal2(z0_, z_mean_0, 2*K.log(z_std_0+1e-8)), -1)\n",
    "        loss -= K.sum(log_stdnormal(z_) , -1)\n",
    "    # don't forget the log_std_sum.\n",
    "    # BE CAUTIOUS!! THE LOG_STD_SUM_0 HAS ALREADY BEEN TAKEN INTO ACCOUNT IN LOSS\n",
    "    kl_loss = loss / n_sample \n",
    "    for z_std in z_stds[1:]:\n",
    "        kl_loss -= K.sum(K.log(1e-8+z_std), -1)    \n",
    "    \n",
    "    return xent_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'dense_20_target_2:0' shape=(?, ?) dtype=float32>, <tf.Tensor 'dense_20/Sigmoid:0' shape=(100, 784) dtype=float32>)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tb = TensorBoard(log_dir='./log/MNIST/10_layer-additional_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f622eb52ed0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "        callbacks=[tb],\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Play with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# build a digit generator that can sample from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = generator.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
